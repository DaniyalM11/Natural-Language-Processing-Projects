{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decc0653",
   "metadata": {},
   "source": [
    "##### CS 583 Assignment 4 \n",
    "##### by Daniyal Mufti\n",
    "##### Transformer Chatbot\n",
    "##### Daily Dialogue Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adf4fd1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b8494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4314b6",
   "metadata": {},
   "source": [
    "### GPU/TPU Setup\n",
    "\n",
    "##### I used an RTX 3090 GPU for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a932835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc7cbe0",
   "metadata": {},
   "source": [
    "### Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3abe51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "# Maximum number of samples to preprocess\n",
    "MAX_SAMPLES = 89862\n",
    "\n",
    "# For tf.data.Dataset\n",
    "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# For Transformer\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da32979",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8df3d",
   "metadata": {},
   "source": [
    "### Load, preprocess & tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886cd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Daniy\\\\tf2-transformer-chatbot-master\\\\ijcnlp_dailydialog\\\\dialogues_text.txt',  encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "Parts = []\n",
    "for line in lines:\n",
    "    \n",
    "        Parts.append(line.replace('\\n', '').split('__eou__'))\n",
    "#print(Parts[1])\n",
    "question = []\n",
    "answer = []\n",
    "for i in range(len(Parts)):\n",
    "    Parts[i] = Parts[i][:-1] \n",
    "#for j in range(20):\n",
    "#    print(range(len(Parts[j])))\n",
    "for y in range(len(Parts)):\n",
    "    for x in range(len(Parts[y])-1):\n",
    "        question.append(Parts[y][x])\n",
    "        answer.append(Parts[y][x+1])\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "  # removing contractions\n",
    "  sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "  sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
    "  sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
    "  sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
    "  sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
    "  sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
    "  sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
    "  sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
    "  sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "  sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "  sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "  sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "  sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "  sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "  sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "  sentence = re.sub(r\"n't\", \" not\", sentence)\n",
    "  sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
    "  sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "for z in range(len(question)):\n",
    "    questions.append(preprocess_sentence(question[z]))\n",
    "for a in range(len(answer)):\n",
    "    answers.append(preprocess_sentence(answer[a]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f274a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: never ! but thank you for inviting me .\n",
      "Sample answer: come on . you ll feel better after we hit the showers .\n"
     ]
    }
   ],
   "source": [
    "print('Sample question: {}'.format(questions[20]))\n",
    "print('Sample answer: {}'.format(answers[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33eeef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tokenizer using tfds for both questions and answers\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# Define start and end token to indicate the start and end of a sentence\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# Vocabulary size plus start and end token\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a9bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question: [3281, 45, 29, 87, 5, 18, 2870, 73, 1]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c47024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, filter and pad sentences\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # tokenize sentence\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "    # check tokenized sentence max length\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # pad tokenized sentences\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ce8587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 8259\n",
      "Number of samples: 89691\n"
     ]
    }
   ],
   "source": [
    "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
    "print('Number of samples: {}'.format(len(questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97bce2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder inputs use the previous target as input\n",
    "# remove START_TOKEN from targets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e114ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ({inputs: (None, 100), dec_inputs: (None, 99)}, {outputs: (None, 99)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da48092",
   "metadata": {},
   "source": [
    "## 3. Build Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbbde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"Calculate the attention weights. \"\"\"\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask to zero out padding tokens\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0dfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "  \n",
    "  def get_config(self):\n",
    "        config = super(MultiHeadAttention,self).get_config()\n",
    "        config.update({\n",
    "            'num_heads':self.num_heads,\n",
    "            'd_model':self.d_model,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.keras.layers.Lambda(lambda inputs:tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth)))(inputs)\n",
    "    return tf.keras.layers.Lambda(lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3]))(inputs)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # split heads\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # scaled dot-product attention\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "    scaled_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.transpose(\n",
    "        scaled_attention, perm=[0, 2, 1, 3]))(scaled_attention)\n",
    "\n",
    "    # concatenation of heads\n",
    "    concat_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model)))(scaled_attention)\n",
    "\n",
    "    # final linear layer\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ab7d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e04cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dd1f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32a61b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c34d423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "  \n",
    "  def get_config(self):\n",
    "\n",
    "        config = super(PositionalEncoding, self).get_config()\n",
    "        config.update({\n",
    "            'position': self.position,\n",
    "            'd_model': self.d_model,\n",
    "            \n",
    "        })\n",
    "        return config\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # apply sin to even index in the array\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # apply cos to odd index in the array\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c58506ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76858b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  add_attention = tf.keras.layers.add([inputs,attention])\n",
    "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  add_attention = tf.keras.layers.add([attention,outputs])\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ba4b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "sample_encoder_layer = encoder_layer(\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_encoder_layer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    sample_encoder_layer, to_file='encoder_layer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a040a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n",
    "  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "582f55b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = encoder(\n",
    "    vocab_size=8192,\n",
    "    num_layers=2,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_encoder\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "   sample_encoder, to_file='encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea2f56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "  add_attention = tf.keras.layers.add([attention1,inputs])    \n",
    "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  add_attention = tf.keras.layers.add([attention2,attention1])\n",
    "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  add_attention = tf.keras.layers.add([outputs,attention2])\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acecc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_layer = decoder_layer(\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_decoder_layer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0e476e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23a556e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "sample_decoder = decoder(\n",
    "    vocab_size=8192,\n",
    "    num_layers=2,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_decoder\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    sample_decoder, to_file='decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82956457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "  # mask the future tokens for decoder inputs at the 1st attention block\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "  # mask the encoder outputs for the 2nd attention block\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcc0e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = transformer(\n",
    "    vocab_size=8192,\n",
    "    num_layers=4,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    sample_transformer, to_file='transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5720341",
   "metadata": {},
   "source": [
    "## 4. Fit, compile & train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b48b352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7000294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = tf.constant(d_model,dtype=tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def get_config(self):\n",
    "        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7a4f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bf57cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3168512     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3695872     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8259)   2122563     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,986,947\n",
      "Trainable params: 8,986,947\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# clear backend\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# initialize and compile model within strategy scope\n",
    "with strategy.scope():\n",
    "  model = transformer(\n",
    "      vocab_size=VOCAB_SIZE,\n",
    "      num_layers=NUM_LAYERS,\n",
    "      units=UNITS,\n",
    "      d_model=D_MODEL,\n",
    "      num_heads=NUM_HEADS,\n",
    "      dropout=DROPOUT)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "974e6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1402/1402 [==============================] - 110s 75ms/step - loss: 0.8662 - accuracy: 0.0311\n",
      "Epoch 2/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.6412 - accuracy: 0.0472\n",
      "Epoch 3/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.5897 - accuracy: 0.0513\n",
      "Epoch 4/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.5487 - accuracy: 0.0549\n",
      "Epoch 5/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.5122 - accuracy: 0.0584\n",
      "Epoch 6/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.4843 - accuracy: 0.0615\n",
      "Epoch 7/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.4611 - accuracy: 0.0644\n",
      "Epoch 8/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.4417 - accuracy: 0.0670\n",
      "Epoch 9/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.4255 - accuracy: 0.0693\n",
      "Epoch 10/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.4115 - accuracy: 0.0714\n",
      "Epoch 11/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3996 - accuracy: 0.0733\n",
      "Epoch 12/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3881 - accuracy: 0.0751\n",
      "Epoch 13/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3788 - accuracy: 0.0765\n",
      "Epoch 14/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3695 - accuracy: 0.0781\n",
      "Epoch 15/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3615 - accuracy: 0.0795\n",
      "Epoch 16/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3541 - accuracy: 0.0808\n",
      "Epoch 17/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3473 - accuracy: 0.0819\n",
      "Epoch 18/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3407 - accuracy: 0.0831\n",
      "Epoch 19/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3351 - accuracy: 0.0840\n",
      "Epoch 20/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3296 - accuracy: 0.0849\n",
      "Epoch 21/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3245 - accuracy: 0.0858\n",
      "Epoch 22/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3194 - accuracy: 0.0868\n",
      "Epoch 23/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3149 - accuracy: 0.0876\n",
      "Epoch 24/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3106 - accuracy: 0.0883\n",
      "Epoch 25/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.3065 - accuracy: 0.0891\n",
      "Epoch 26/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.3027 - accuracy: 0.0898\n",
      "Epoch 27/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2990 - accuracy: 0.0904\n",
      "Epoch 28/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2957 - accuracy: 0.0909\n",
      "Epoch 29/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2925 - accuracy: 0.0917\n",
      "Epoch 30/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2890 - accuracy: 0.0923\n",
      "Epoch 31/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2862 - accuracy: 0.0929\n",
      "Epoch 32/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2831 - accuracy: 0.0934\n",
      "Epoch 33/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2807 - accuracy: 0.0940\n",
      "Epoch 34/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2778 - accuracy: 0.0945\n",
      "Epoch 35/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2752 - accuracy: 0.0950\n",
      "Epoch 36/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2728 - accuracy: 0.0954\n",
      "Epoch 37/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2704 - accuracy: 0.0958\n",
      "Epoch 38/300\n",
      "1402/1402 [==============================] - 487s 347ms/step - loss: 0.2681 - accuracy: 0.0963\n",
      "Epoch 39/300\n",
      "1402/1402 [==============================] - 107s 76ms/step - loss: 0.2660 - accuracy: 0.0967\n",
      "Epoch 40/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2636 - accuracy: 0.0972\n",
      "Epoch 41/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2616 - accuracy: 0.0976\n",
      "Epoch 42/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2597 - accuracy: 0.0980\n",
      "Epoch 43/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2577 - accuracy: 0.0983\n",
      "Epoch 44/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2556 - accuracy: 0.0987\n",
      "Epoch 45/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2540 - accuracy: 0.0991\n",
      "Epoch 46/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2523 - accuracy: 0.0995\n",
      "Epoch 47/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2507 - accuracy: 0.0998\n",
      "Epoch 48/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2488 - accuracy: 0.1001\n",
      "Epoch 49/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2470 - accuracy: 0.1004\n",
      "Epoch 50/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2454 - accuracy: 0.1008\n",
      "Epoch 51/300\n",
      "1402/1402 [==============================] - 106s 76ms/step - loss: 0.2440 - accuracy: 0.1011\n",
      "Epoch 52/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2424 - accuracy: 0.1013\n",
      "Epoch 53/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2411 - accuracy: 0.1017\n",
      "Epoch 54/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2393 - accuracy: 0.1020\n",
      "Epoch 55/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2381 - accuracy: 0.1022\n",
      "Epoch 56/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2367 - accuracy: 0.1025\n",
      "Epoch 57/300\n",
      "1402/1402 [==============================] - 106s 75ms/step - loss: 0.2353 - accuracy: 0.1028\n",
      "Epoch 58/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2338 - accuracy: 0.1031\n",
      "Epoch 59/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2326 - accuracy: 0.1034\n",
      "Epoch 60/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2317 - accuracy: 0.1035\n",
      "Epoch 61/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2302 - accuracy: 0.1039\n",
      "Epoch 62/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2293 - accuracy: 0.1040\n",
      "Epoch 63/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2279 - accuracy: 0.1043\n",
      "Epoch 64/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2266 - accuracy: 0.1046\n",
      "Epoch 65/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2253 - accuracy: 0.1048\n",
      "Epoch 66/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2246 - accuracy: 0.1051\n",
      "Epoch 67/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2234 - accuracy: 0.1052\n",
      "Epoch 68/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2221 - accuracy: 0.1055\n",
      "Epoch 69/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2212 - accuracy: 0.1056\n",
      "Epoch 70/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2203 - accuracy: 0.1059\n",
      "Epoch 71/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2191 - accuracy: 0.1061\n",
      "Epoch 72/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2179 - accuracy: 0.1064\n",
      "Epoch 73/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2171 - accuracy: 0.1065\n",
      "Epoch 74/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2161 - accuracy: 0.1068\n",
      "Epoch 75/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2152 - accuracy: 0.1069\n",
      "Epoch 76/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2143 - accuracy: 0.1071\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2132 - accuracy: 0.1074\n",
      "Epoch 78/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2120 - accuracy: 0.1076\n",
      "Epoch 79/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2113 - accuracy: 0.1077\n",
      "Epoch 80/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2105 - accuracy: 0.1079\n",
      "Epoch 81/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2092 - accuracy: 0.1082\n",
      "Epoch 82/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2086 - accuracy: 0.1083\n",
      "Epoch 83/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2075 - accuracy: 0.1085\n",
      "Epoch 84/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2067 - accuracy: 0.1087\n",
      "Epoch 85/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2060 - accuracy: 0.1088\n",
      "Epoch 86/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2053 - accuracy: 0.1090\n",
      "Epoch 87/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2046 - accuracy: 0.1091\n",
      "Epoch 88/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2035 - accuracy: 0.1094\n",
      "Epoch 89/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2028 - accuracy: 0.1094\n",
      "Epoch 90/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2020 - accuracy: 0.1097\n",
      "Epoch 91/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2012 - accuracy: 0.1098\n",
      "Epoch 92/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.2003 - accuracy: 0.1100\n",
      "Epoch 93/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1996 - accuracy: 0.1101\n",
      "Epoch 94/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1991 - accuracy: 0.1103\n",
      "Epoch 95/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1983 - accuracy: 0.1104\n",
      "Epoch 96/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1974 - accuracy: 0.1105\n",
      "Epoch 97/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1967 - accuracy: 0.1108\n",
      "Epoch 98/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1963 - accuracy: 0.1108\n",
      "Epoch 99/300\n",
      "1402/1402 [==============================] - 104s 74ms/step - loss: 0.1954 - accuracy: 0.1110\n",
      "Epoch 100/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1949 - accuracy: 0.1111\n",
      "Epoch 101/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1940 - accuracy: 0.1113\n",
      "Epoch 102/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1936 - accuracy: 0.1114\n",
      "Epoch 103/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1930 - accuracy: 0.1115\n",
      "Epoch 104/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1922 - accuracy: 0.1116\n",
      "Epoch 105/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1915 - accuracy: 0.1119\n",
      "Epoch 106/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1908 - accuracy: 0.1119\n",
      "Epoch 107/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1902 - accuracy: 0.1121\n",
      "Epoch 108/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1896 - accuracy: 0.1122\n",
      "Epoch 109/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1888 - accuracy: 0.1124\n",
      "Epoch 110/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1883 - accuracy: 0.1125\n",
      "Epoch 111/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1878 - accuracy: 0.1125\n",
      "Epoch 112/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1870 - accuracy: 0.1127\n",
      "Epoch 113/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1863 - accuracy: 0.1129\n",
      "Epoch 114/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1858 - accuracy: 0.1130\n",
      "Epoch 115/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1855 - accuracy: 0.1131\n",
      "Epoch 116/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1847 - accuracy: 0.1132\n",
      "Epoch 117/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1843 - accuracy: 0.1133\n",
      "Epoch 118/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1836 - accuracy: 0.1135\n",
      "Epoch 119/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1833 - accuracy: 0.1135\n",
      "Epoch 120/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1825 - accuracy: 0.1137\n",
      "Epoch 121/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1824 - accuracy: 0.1136\n",
      "Epoch 122/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1817 - accuracy: 0.1138\n",
      "Epoch 123/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1810 - accuracy: 0.1140\n",
      "Epoch 124/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1806 - accuracy: 0.1141\n",
      "Epoch 125/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1799 - accuracy: 0.1142\n",
      "Epoch 126/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1793 - accuracy: 0.1144\n",
      "Epoch 127/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1791 - accuracy: 0.1144\n",
      "Epoch 128/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1785 - accuracy: 0.1145\n",
      "Epoch 129/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1780 - accuracy: 0.1147\n",
      "Epoch 130/300\n",
      "1402/1402 [==============================] - 104s 75ms/step - loss: 0.1775 - accuracy: 0.1147\n",
      "Epoch 131/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1767 - accuracy: 0.1149\n",
      "Epoch 132/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1764 - accuracy: 0.1150\n",
      "Epoch 133/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1760 - accuracy: 0.1151\n",
      "Epoch 134/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1754 - accuracy: 0.1152\n",
      "Epoch 135/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1750 - accuracy: 0.1153\n",
      "Epoch 136/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1744 - accuracy: 0.1154\n",
      "Epoch 137/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1741 - accuracy: 0.1155\n",
      "Epoch 138/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1737 - accuracy: 0.1155\n",
      "Epoch 139/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1731 - accuracy: 0.1156\n",
      "Epoch 140/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1723 - accuracy: 0.1158\n",
      "Epoch 141/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1721 - accuracy: 0.1159\n",
      "Epoch 142/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1716 - accuracy: 0.1160\n",
      "Epoch 143/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1714 - accuracy: 0.1159\n",
      "Epoch 144/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1711 - accuracy: 0.1161\n",
      "Epoch 145/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1701 - accuracy: 0.1163\n",
      "Epoch 146/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1699 - accuracy: 0.1163\n",
      "Epoch 147/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1698 - accuracy: 0.1164\n",
      "Epoch 148/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1694 - accuracy: 0.1164\n",
      "Epoch 149/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1688 - accuracy: 0.1166\n",
      "Epoch 150/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1683 - accuracy: 0.1167\n",
      "Epoch 151/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1681 - accuracy: 0.1168\n",
      "Epoch 152/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1676 - accuracy: 0.1169\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1668 - accuracy: 0.1169\n",
      "Epoch 154/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1666 - accuracy: 0.1171\n",
      "Epoch 155/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1664 - accuracy: 0.1171\n",
      "Epoch 156/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1659 - accuracy: 0.1172\n",
      "Epoch 157/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1655 - accuracy: 0.1173\n",
      "Epoch 158/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1651 - accuracy: 0.1174\n",
      "Epoch 159/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1648 - accuracy: 0.1175\n",
      "Epoch 160/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1645 - accuracy: 0.1175\n",
      "Epoch 161/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1641 - accuracy: 0.1176\n",
      "Epoch 162/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1635 - accuracy: 0.1177\n",
      "Epoch 163/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1633 - accuracy: 0.1178\n",
      "Epoch 164/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1628 - accuracy: 0.1178\n",
      "Epoch 165/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1625 - accuracy: 0.1180\n",
      "Epoch 166/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1619 - accuracy: 0.1180\n",
      "Epoch 167/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1618 - accuracy: 0.1181\n",
      "Epoch 168/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1615 - accuracy: 0.1181\n",
      "Epoch 169/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1611 - accuracy: 0.1182\n",
      "Epoch 170/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1606 - accuracy: 0.1183\n",
      "Epoch 171/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1604 - accuracy: 0.1184\n",
      "Epoch 172/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1599 - accuracy: 0.1185\n",
      "Epoch 173/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1600 - accuracy: 0.1185\n",
      "Epoch 174/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1594 - accuracy: 0.1186\n",
      "Epoch 175/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1588 - accuracy: 0.1187\n",
      "Epoch 176/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1587 - accuracy: 0.1187\n",
      "Epoch 177/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1582 - accuracy: 0.1189\n",
      "Epoch 178/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1579 - accuracy: 0.1189\n",
      "Epoch 179/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1576 - accuracy: 0.1190\n",
      "Epoch 180/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1571 - accuracy: 0.1191\n",
      "Epoch 181/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1571 - accuracy: 0.1190\n",
      "Epoch 182/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1570 - accuracy: 0.1192\n",
      "Epoch 183/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1566 - accuracy: 0.1192\n",
      "Epoch 184/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1560 - accuracy: 0.1193\n",
      "Epoch 185/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1556 - accuracy: 0.1194\n",
      "Epoch 186/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1555 - accuracy: 0.1194\n",
      "Epoch 187/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1550 - accuracy: 0.1194\n",
      "Epoch 188/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1549 - accuracy: 0.1195\n",
      "Epoch 189/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1543 - accuracy: 0.1197\n",
      "Epoch 190/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1541 - accuracy: 0.1197\n",
      "Epoch 191/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1539 - accuracy: 0.1197\n",
      "Epoch 192/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1535 - accuracy: 0.1199\n",
      "Epoch 193/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1534 - accuracy: 0.1199\n",
      "Epoch 194/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1530 - accuracy: 0.1200\n",
      "Epoch 195/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1529 - accuracy: 0.1200\n",
      "Epoch 196/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1522 - accuracy: 0.1201\n",
      "Epoch 197/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1520 - accuracy: 0.1202\n",
      "Epoch 198/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1517 - accuracy: 0.1203\n",
      "Epoch 199/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1517 - accuracy: 0.1203\n",
      "Epoch 200/300\n",
      "1402/1402 [==============================] - 104s 74ms/step - loss: 0.1514 - accuracy: 0.1203\n",
      "Epoch 201/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1510 - accuracy: 0.1204\n",
      "Epoch 202/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1506 - accuracy: 0.1206\n",
      "Epoch 203/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1505 - accuracy: 0.1205\n",
      "Epoch 204/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1503 - accuracy: 0.1207\n",
      "Epoch 205/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1495 - accuracy: 0.1208\n",
      "Epoch 206/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1496 - accuracy: 0.1208\n",
      "Epoch 207/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1495 - accuracy: 0.1207\n",
      "Epoch 208/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1492 - accuracy: 0.1207\n",
      "Epoch 209/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1488 - accuracy: 0.1209\n",
      "Epoch 210/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1487 - accuracy: 0.1209\n",
      "Epoch 211/300\n",
      "1402/1402 [==============================] - 104s 74ms/step - loss: 0.1483 - accuracy: 0.1210\n",
      "Epoch 212/300\n",
      "1402/1402 [==============================] - 104s 75ms/step - loss: 0.1481 - accuracy: 0.1210\n",
      "Epoch 213/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1474 - accuracy: 0.1213\n",
      "Epoch 214/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1476 - accuracy: 0.1211\n",
      "Epoch 215/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1470 - accuracy: 0.1212\n",
      "Epoch 216/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1468 - accuracy: 0.1213\n",
      "Epoch 217/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1467 - accuracy: 0.1214\n",
      "Epoch 218/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1465 - accuracy: 0.1214\n",
      "Epoch 219/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1463 - accuracy: 0.1215\n",
      "Epoch 220/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1460 - accuracy: 0.1215\n",
      "Epoch 221/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1461 - accuracy: 0.1215\n",
      "Epoch 222/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1456 - accuracy: 0.1216\n",
      "Epoch 223/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1453 - accuracy: 0.1217\n",
      "Epoch 224/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1450 - accuracy: 0.1217\n",
      "Epoch 225/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1447 - accuracy: 0.1218\n",
      "Epoch 226/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1446 - accuracy: 0.1218\n",
      "Epoch 227/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1446 - accuracy: 0.1218\n",
      "Epoch 228/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1443 - accuracy: 0.1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1440 - accuracy: 0.1219\n",
      "Epoch 230/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1437 - accuracy: 0.1220\n",
      "Epoch 231/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1435 - accuracy: 0.1220\n",
      "Epoch 232/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1436 - accuracy: 0.1221\n",
      "Epoch 233/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1431 - accuracy: 0.1222\n",
      "Epoch 234/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1430 - accuracy: 0.1222\n",
      "Epoch 235/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1428 - accuracy: 0.1222\n",
      "Epoch 236/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1426 - accuracy: 0.1223\n",
      "Epoch 237/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1422 - accuracy: 0.1224\n",
      "Epoch 238/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1419 - accuracy: 0.1224\n",
      "Epoch 239/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1417 - accuracy: 0.1224\n",
      "Epoch 240/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1416 - accuracy: 0.1225\n",
      "Epoch 241/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1416 - accuracy: 0.1225\n",
      "Epoch 242/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1411 - accuracy: 0.1226\n",
      "Epoch 243/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1410 - accuracy: 0.1226\n",
      "Epoch 244/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1410 - accuracy: 0.1226\n",
      "Epoch 245/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1405 - accuracy: 0.1227\n",
      "Epoch 246/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1402 - accuracy: 0.1228\n",
      "Epoch 247/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1400 - accuracy: 0.1229\n",
      "Epoch 248/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1399 - accuracy: 0.1229\n",
      "Epoch 249/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1394 - accuracy: 0.1230\n",
      "Epoch 250/300\n",
      "1402/1402 [==============================] - 104s 74ms/step - loss: 0.1394 - accuracy: 0.1230\n",
      "Epoch 251/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1392 - accuracy: 0.1231\n",
      "Epoch 252/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1390 - accuracy: 0.1231\n",
      "Epoch 253/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1389 - accuracy: 0.1231\n",
      "Epoch 254/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1387 - accuracy: 0.1231\n",
      "Epoch 255/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1387 - accuracy: 0.1231\n",
      "Epoch 256/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1382 - accuracy: 0.1233\n",
      "Epoch 257/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1381 - accuracy: 0.1233\n",
      "Epoch 258/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1378 - accuracy: 0.1233\n",
      "Epoch 259/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1379 - accuracy: 0.1233\n",
      "Epoch 260/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1376 - accuracy: 0.1234\n",
      "Epoch 261/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1375 - accuracy: 0.1235\n",
      "Epoch 262/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1372 - accuracy: 0.1235\n",
      "Epoch 263/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1371 - accuracy: 0.1235\n",
      "Epoch 264/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1370 - accuracy: 0.1236\n",
      "Epoch 265/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1367 - accuracy: 0.1237\n",
      "Epoch 266/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1365 - accuracy: 0.1237\n",
      "Epoch 267/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1364 - accuracy: 0.1237\n",
      "Epoch 268/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1361 - accuracy: 0.1238\n",
      "Epoch 269/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1359 - accuracy: 0.1238\n",
      "Epoch 270/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1355 - accuracy: 0.1239\n",
      "Epoch 271/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1355 - accuracy: 0.1239\n",
      "Epoch 272/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1353 - accuracy: 0.1239\n",
      "Epoch 273/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1352 - accuracy: 0.1239\n",
      "Epoch 274/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1351 - accuracy: 0.1240\n",
      "Epoch 275/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1346 - accuracy: 0.1241\n",
      "Epoch 276/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1345 - accuracy: 0.1241\n",
      "Epoch 277/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1342 - accuracy: 0.1241\n",
      "Epoch 278/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1342 - accuracy: 0.1242\n",
      "Epoch 279/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1340 - accuracy: 0.1243\n",
      "Epoch 280/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1342 - accuracy: 0.1242\n",
      "Epoch 281/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1338 - accuracy: 0.1243\n",
      "Epoch 282/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1338 - accuracy: 0.1243\n",
      "Epoch 283/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1338 - accuracy: 0.1243\n",
      "Epoch 284/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1334 - accuracy: 0.1243\n",
      "Epoch 285/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1336 - accuracy: 0.1243\n",
      "Epoch 286/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1331 - accuracy: 0.1245\n",
      "Epoch 287/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1328 - accuracy: 0.1245\n",
      "Epoch 288/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1324 - accuracy: 0.1246\n",
      "Epoch 289/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1325 - accuracy: 0.1246\n",
      "Epoch 290/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1324 - accuracy: 0.1246\n",
      "Epoch 291/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1322 - accuracy: 0.1246\n",
      "Epoch 292/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1317 - accuracy: 0.1247\n",
      "Epoch 293/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1315 - accuracy: 0.1249\n",
      "Epoch 294/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1315 - accuracy: 0.1248\n",
      "Epoch 295/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1315 - accuracy: 0.1247\n",
      "Epoch 296/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1316 - accuracy: 0.1247\n",
      "Epoch 297/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1311 - accuracy: 0.1249\n",
      "Epoch 298/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1306 - accuracy: 0.1250\n",
      "Epoch 299/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1306 - accuracy: 0.1250\n",
      "Epoch 300/300\n",
      "1402/1402 [==============================] - 105s 75ms/step - loss: 0.1304 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1da190a13d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2590b",
   "metadata": {},
   "source": [
    "## 5. Evaluate & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7fcf31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # concatenated the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69dc8ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Where have you been?\n",
      "Output: i just got back from london .\n"
     ]
    }
   ],
   "source": [
    "output = predict('Where have you been?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1b27b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: It's a trap\n",
      "Output: i have no ticket .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "400a83dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I am not crazy, my mother had me tested.\n",
      "Output: that is the problem with it ?\n",
      "\n",
      "Input: that is the problem with it ?\n",
      "Output: i have a meeting in my room , and the doctor s does not mind . it s nothing serious .\n",
      "\n",
      "Input: i have a meeting in my room , and the doctor s does not mind . it s nothing serious .\n",
      "Output: i m afraid there s no problem . don t worry . there s no needs a it big bedsimitate you .\n",
      "\n",
      "Input: i m afraid there s no problem . don t worry . there s no needs a it big bedsimitate you .\n",
      "Output: thanks . i can t wait to see my husband though . i m going to make a lot of fun . why don t he give me a call , so take it back ? i ll gets taken care of the way that i know your husband over there . i would love to get my card !\n",
      "\n",
      "Input: thanks . i can t wait to see my husband though . i m going to make a lot of fun . why don t he give me a call , so take it back ? i ll gets taken care of the way that i know your husband over there . i would love to get my card !\n",
      "Output: be careful , re not my boss . i m not going to be back friends this afternoon . i don t want to get a drink tonight . i m going to a drink or something . i know how you re going to be a friend about a drink or a drink too .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feed the model with its previous output\n",
    "sentence = 'I am not crazy, my mother had me tested.'\n",
    "for _ in range(5):\n",
    "  sentence = predict(sentence)\n",
    "  print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
